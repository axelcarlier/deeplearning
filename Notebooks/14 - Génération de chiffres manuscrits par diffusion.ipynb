{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","toc_visible":true,"authorship_tag":"ABX9TyP0TM4KOPb759bpcUaVxTR1"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["Ce TP est une illustration des méthodes de diffusion permettant la génération d'image. Il reprend les éléments présentés dans l'article **Denoising Diffusion Probabilistic Models** de Jonathan Ho et al. paru en 2020, simplifié pour être réalisable en une séance de TP."],"metadata":{"id":"EdWJl-7ookmF"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"fe0shJVJjss3"},"outputs":[],"source":["import tensorflow\n","from tensorflow import keras\n","\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import math"]},{"cell_type":"markdown","source":["# Chargement des données\n","\n","Pour ce TP, nous utiliserons simplement les données d'entraînement de la base de données MNIST."],"metadata":{"id":"uJ56DzmajycA"}},{"cell_type":"code","source":["(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()"],"metadata":{"id":"uKesZxz0kUcG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Passe forward: image $ \\rightarrow$ noise\n","\n","\n","Pour commencer, nous allons illustrer la passe *forward* consistant à bruiter itérativement une image jusqu'à ce qu'elle devienne une image de bruit gaussien centré réduit.\n","\n","\n","<center> <img src=\"https://drive.google.com/uc?id=1igVT9w15wgs-8YDFK8frhBkRkRitSRnj\" width=500></center>\n","\n","On procède en $T$ étapes, et à chaque étape on peut exprimer la distribution de $\\boldsymbol{x}_t$ à partir de celle de $\\boldsymbol{x}_{t-1}$ de la manière suivante :\n","\n","$$q(\\boldsymbol{x}_t \\mid \\boldsymbol{x}_{t-1}) = \\mathcal{N}(\\boldsymbol{x}_t ; \\sqrt{1 - \\beta_t} \\, \\boldsymbol{x}_{t-1}, \\beta_t \\boldsymbol{I}) \\quad\n","$$\n","\n","\n","où $\\beta_t$ est un paramètre qui programme l'ajout progressif de bruit.\n","\n","Avec des $\\beta_t$ bien choisis, les pixels de l'image suivent à l'issue du processus une loi normale centrée réduite.\n","\n","Si l'on pose $\\alpha_t = 1 - \\beta_t$ et $\\overline{\\alpha}_t = \\prod_{s=1}^t \\alpha_s$, on peut montrer que :    \n","\n","$$q(\\boldsymbol{x}_T \\mid \\boldsymbol{x}_{0}) = \\mathcal{N}(\\boldsymbol{x}_T ; \\sqrt{\\overline{\\alpha}_T} \\, \\boldsymbol{x}_{0}, (1 - \\overline{\\alpha}_T) \\boldsymbol{I}) \\quad$$\n","\n","Le choix des hyperparamètres $T$ et $\\beta_t$ est crucial pour le bon fonctionnement de l'algorithme. Dans l'article original, $T = 1000$ (!!) et les $\\beta_t$ sont répartis linéairement entre $\\beta_1 = 1e-4$ et $\\beta_T=0.02$. Les auteurs mentionnent l'importance d'avoir des $\\beta_t$ petits pour obtenir des échantillons réalistes.\n","\n","\n","Dans ce TP, nous allons faire des choix simplificateurs afin de pouvoir exécuter l'algorithme dans les 2h imparties. Ainsi, nous choisirons $T = 10$, et $\\beta_1 = 0.1$, $\\beta_T=0.8$. Nous verrons malheureusement que les échantillons que nous générerons ne serons pas parfaitement réalistes, mais cela nous permettra quand même d'avoir une preuve de concept !\n","\n"],"metadata":{"id":"YCTp8PXClD9w"}},{"cell_type":"code","source":["# 10 pas de diffusion\n","T = 10\n","\n","# Programmation des beta_t\n","beta_1 = 0.1\n","beta_T = 0.8\n","\n","### A COMPLETER ###\n","# Les beta_t se répartissent linéairement entre beta_1 et beta_T\n","beta = ...\n","print('beta = ' + str(beta))\n"],"metadata":{"id":"gSHRRPWGxTxl"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Résultat attendu :**\n","    \n","```\n","beta = [0.         0.1        0.17777778 0.25555556 0.33333333 0.41111111\n"," 0.48888889 0.56666667 0.64444444 0.72222222 0.8       ]\n"," ```"],"metadata":{"id":"LJmVy-YivC8I"}},{"cell_type":"markdown","source":["**Travail à faire** : Compléter la définition des $\\alpha_t$ et des $\\overline{\\alpha}_t$, et vérifiez que la distribution finale obtenue pour $\\boldsymbol{x}_T$ est bien proche d'une loi normale centrée réduite."],"metadata":{"id":"TI4qmlestpmx"}},{"cell_type":"code","source":["### A COMPLETER ###\n","alpha = ...\n","alpha_barre = ...\n","\n","# Moyenne de x_T\n","mu_x_T = ...\n","print('Moyenne de x_T = ' + str(mu_x_T))\n","\n","# Variance de x_T\n","sigma_x_T = ...\n","print('Variance de x_T = ' + str(sigma_x_T))"],"metadata":{"id":"jneBj7A0xx91"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Résultat attendu :**    \n","```\n","Moyenne de x_T = 0.03076020665577701\n","Variance de x_T = 0.9990538096864939\n","```"],"metadata":{"id":"dqrh_1nywfjs"}},{"cell_type":"markdown","source":["Les images doivent être normalisées entre -1 et 1 avant de démarrer le processus de diffusion."],"metadata":{"id":"MnDmIr17xUz3"}},{"cell_type":"code","source":["def normalize(img):\n","  img = img.astype('float')\n","  return (img-128)/128\n","\n","def denormalize(img):\n","  img = 255*(img+np.min(img))/(np.max(img) - np.min(img))\n","  return img.astype('uint8')"],"metadata":{"id":"QbWlGdWYoFf3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Diffusion progressive\n","\n","Si $\\boldsymbol{x}_{t-1}$ est l'image bruitée au pas $t-1$, et $\\boldsymbol{\\epsilon}$ un bruit échantillonné sur toute la dimension de l'image, on peut obtenir $\\boldsymbol{x}_t$ en calculant :\n","\n","$$\n","\\boldsymbol{x}_t = \\sqrt{\\alpha_t} \\, \\boldsymbol{x}_{t-1} + \\sqrt{\\beta_t} \\, \\boldsymbol{\\epsilon}\n","$$"],"metadata":{"id":"3vHm-vwmi9eu"}},{"cell_type":"code","source":["### A COMPLETER ###\n","# On prend une image de la base de donnée comme point de départ\n","x_0 = normalize(x_train[0])\n","\n","# On prépare le vecteur des x_t que l'on va remplir au fur et à mesure\n","x = np.zeros((T+1, 28, 28))\n","\n","plt.figure(figsize=(20, 10))\n","\n","for t in range(T+1):\n","  if t==0:\n","    x[t] = ...\n","  else:\n","    # Echantillonnage d'un bruit gaussien epsilon\n","    epsilon = ...\n","\n","    # Calcul de x_t à partir de x_{t-1}\n","    x[t] = ...\n","\n","  # Affichage de x_t\n","  plt.subplot(1, T+1, t+1)\n","  plt.title(f't={t}')\n","  plt.imshow(x[t], cmap='gray')\n","  plt.axis('off')\n","\n","plt.show()"],"metadata":{"id":"2wAAotlWlI-j"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Diffusion directe\n","\n","Il sera plus aisé pendant l'apprentissage d'obtenir directement une expression de $\\boldsymbol{x}_t$ à partir de $\\boldsymbol{x}_0$ grâce à la relation :     \n","\n","$$q(\\boldsymbol{x}_t \\mid \\boldsymbol{x}_{0}) = \\mathcal{N}(\\boldsymbol{x}_t ; \\sqrt{\\overline{\\alpha}_t} \\, \\boldsymbol{x}_{0}, (1 - \\overline{\\alpha}_t) \\boldsymbol{I}) \\quad$$\n","\n","Si $\\boldsymbol{x}_{0}$ est l'image originale, et $\\boldsymbol{\\epsilon}$ un bruit échantillonné sur toute la dimension de l'image, on peut donc obtenir $\\boldsymbol{x}_t$ en calculant :\n","\n","$$\n","\\boldsymbol{x}_t = \\sqrt{\\overline{\\alpha}_t} \\, \\boldsymbol{x}_{0} + \\sqrt{1 - \\overline{\\alpha}_t} \\, \\boldsymbol{\\epsilon}\n","$$"],"metadata":{"id":"GERUkZuIjBQr"}},{"cell_type":"code","source":["### A COMPLETER ###\n","\n","# On prend une image de la base de donnée comme point de départ\n","x_0 = normalize(x_train[0])\n","\n","# On prépare le vecteur des x_t que l'on va remplir au fur et à mesure\n","x = np.zeros((T+1, 28, 28))\n","\n","plt.figure(figsize=(20, 10))\n","\n","for t in range(T+1):\n","  if t==0:\n","    x[t] = ...\n","  else:\n","    # Echantillonnage d'un bruit gaussien epsilon\n","    epsilon = ...\n","\n","    # Calcul de x_t à partir de x_{t-1}\n","    x[t] = ...\n","\n","  # Affichage de x_t\n","  plt.subplot(1, T+1, t+1)\n","  plt.title(f't={t}')\n","  plt.imshow(x[t], cmap='gray')\n","  plt.axis('off')\n","\n","plt.show()\n"],"metadata":{"id":"Cj8D-uwfj2ns"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Entraînement du modèle\n","\n","\n","<center> <img src=\"https://drive.google.com/uc?id=1cNaxGhMFsWzdZDBJTdh2CAyKWW34T4W3\" width=500></center>\n","\n","Nous allons d'abord préparer les entrées ($\\boldsymbol{x}_0$ et $t$) et la sortie associée ($\\boldsymbol{\\epsilon}$) à donner au réseau au moyen d'un objet Sequence.\n","\n","Puis nous allons définir le réseau U-Net et lancer l'apprentissage."],"metadata":{"id":"WsDlLfiF2xKb"}},{"cell_type":"markdown","source":["### Mise en batches avec une Sequence"],"metadata":{"id":"jEZDLsr50jEc"}},{"cell_type":"code","source":["from tensorflow.keras.utils import Sequence\n","\n","### A COMPLETER ###\n","class DiffusionSequence(Sequence):\n","    # Initialisation de la séquence avec différents paramètres\n","    def __init__(self, x_set, batch_size, beta):\n","        self.x = x_set\n","        self.batch_size = batch_size\n","        self.indices = np.arange(x_set.shape[0])\n","        self.beta = beta\n","        self.alpha = ...\n","        self.alpha_barre = ...\n","        np.random.shuffle(self.indices) # Les indices permettent d'accéder\n","        # aux données sont randomisés à chaque epoch pour varier la composition\n","        # des batches au cours de l'entraînement\n","\n","    # Fonction calculant le nombre de pas de descente du gradient par epoch\n","    def __len__(self):\n","        return int(np.floor(len(self.x) / float(self.batch_size)))\n","\n","\n","    # Fonction appelée à chaque nouveau batch : préparation des données et labels associés\n","    # On va appliquer la diffusion directe à des images de la base de donnée\n","    # Pour cela nous allons générer des bruits epsilon, qui seront les cibles (batch_y)\n","    # Pour chaque image, nous allons tirer aléatoirement un pas t entre 1 et T et\n","    # générer l'image bruitée x_t correspondante à l'aide du epsilon\n","    def __getitem__(self, idx):\n","\n","        # La cible à prédire sera un bruit gaussien centré réduit de taille (B, 28, 28)\n","        batch_y = ...\n","\n","        # Sélection des images dans la base\n","        batch_x = self.x[self.indices[idx * self.batch_size:(idx + 1) * self.batch_size]].astype('float')\n","        batch_x = normalize(batch_x)\n","\n","        # Echantillonnage de t entre 1 et T\n","        batch_t = ...\n","\n","        for i in range(self.batch_size):\n","          # Pour chaque élément de batch_x, on remplace l'image originale (x_0) par\n","          # l'image bruitée générée (x_t)\n","          batch_x[i] = ...\n","\n","        # On normalise les t qui seront fournis à l'entrée du réseau\n","        batch_t = batch_t/T\n","\n","        # On retourne les entrées à fournir au réseau (batch_x, batch_t) et la sortie batch_y\n","        return ((np.array(batch_x), batch_t), np.array(batch_y))\n","\n","    # Fonction appelée à la fin d'un epoch ; on randomise les indices d'accès aux données\n","    def on_epoch_end(self):\n","        np.random.shuffle(self.indices)\n","\n"],"metadata":{"id":"YUPfVKKWduEt"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Instanciation de la séquence et affichage d'un couple donnée/label"],"metadata":{"id":"eZCA8Ad92mQ3"}},{"cell_type":"code","source":["train_gen = DiffusionSequence(x_train, 32, beta)"],"metadata":{"id":"w53AcU-9l1GY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["x, batch_y = train_gen.__getitem__(0)\n","batch_x, batch_t = x\n","\n","plt.subplot(1,2,1)\n","plt.imshow(batch_x[0], cmap='gray')\n","plt.title(f't={batch_t[0]*T}')\n","\n","plt.subplot(1,2,2)\n","plt.imshow(batch_y[0], cmap='gray')\n","\n","plt.show()"],"metadata":{"id":"4G0FxE5_l8kr"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Création du modèle\n","\n","Pour cette partie je vous fournis un modèle qui devrait suffire pour générer les chiffres manuscrits; ce modèle prend deux entrées $x_t$ et $t$ !"],"metadata":{"id":"oPIO_GQgZ2TS"}},{"cell_type":"code","source":["from keras.layers import Conv2D, Input, MaxPooling2D, Conv2DTranspose, concatenate, Dense, Reshape\n","from keras.models import Model\n","\n","def create_unet(image_size=28):\n","  input_image=Input((image_size, image_size, 1))\n","  input_step = Input((1,))\n","\n","  step_preproc = Dense(image_size*image_size, activation='relu')(input_step)\n","  step_preproc = Reshape((image_size, image_size, 1))(step_preproc)\n","\n","  input_layer = concatenate([input_image, step_preproc], axis=3)\n","\n","  conv1 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(input_image)\n","  conv1 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1)\n","  pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n","\n","  conv2 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)\n","  conv2 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2)\n","  pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n","\n","  conv3 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)\n","  conv3 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)\n","\n","  up4 = Conv2DTranspose(64, 2, 2, padding='same', activation='relu')(conv3)\n","  merge4 = concatenate([conv2,up4], axis = 3)\n","  conv4 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge4)\n","  conv4 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)\n","\n","  up5 = Conv2DTranspose(32, 2, 2, padding='same', activation='relu')(conv4)\n","  merge5 = concatenate([conv1,up5], axis = 3)\n","  conv5 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge5)\n","  conv5 = Conv2D(1, 1, activation = 'linear', padding = 'same', kernel_initializer = 'he_normal')(conv5)\n","\n","  model = Model(inputs=[input_image, input_step], outputs=conv5)\n","\n","  return model"],"metadata":{"id":"y-lCUiTXZ0lV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = create_unet()\n","model.summary()"],"metadata":{"id":"ovtnqTZNdT9b"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Entraînement du modèle"],"metadata":{"id":"OapFuA8D3xfW"}},{"cell_type":"code","source":["model = create_unet()\n","opt = keras.optimizers.Adam(learning_rate=1e-3)\n","model.compile(loss='mse', optimizer=opt)\n","\n","train_gen = DiffusionSequence(x_train, 32, beta)\n","\n","model.fit(train_gen, epochs=20)\n"],"metadata":{"id":"ud_cAWineB09"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Passe backward: noise -> image\n","\n","Dans cette partie, nous allons nous servir de la prédiction du réseau pour débruiter itérativement une image de bruit et arriver, on l'espère, à générer une image.\n","\n","Pour commencer, nous allons vérifier si le bruit $\\boldsymbol{\\epsilon}_\\theta (\\boldsymbol{x}_t, t)$ prédit par le réseau est pertinent.\n","\n","Pour cela, nous allons générer des images bruitées $\\boldsymbol{x}_t$ comme précédemment.\n","Pour chaque image, nous allons faire estimer le bruit par le réseau, et essayer de retrouver l'image originale à l'aide de la formule :\n","\n","$$\n","\\boldsymbol{x}_{0} = \\frac{1}{\\overline{\\alpha}_t} \\left( \\boldsymbol{x}_t - \\sqrt{1 - \\overline{\\alpha}_t} \\, \\boldsymbol{\\epsilon}_\\theta (\\boldsymbol{x}_t, t) \\right)\n","$$"],"metadata":{"id":"ux_mFZKb3_iA"}},{"cell_type":"code","source":["### A COMPLETER ###\n","# On prend une image de la base de donnée de test (jamais vue par le réseau) comme point de départ\n","x_0 = normalize(x_test[0])\n","\n","# On prépare le vecteur des x_t que l'on va remplir au fur et à mesure\n","x = np.zeros((T+1, 28, 28))\n","\n","# On prépare également le vecteur des x_0 débruités que l'on va remplir au fur et à mesure\n","denoised = np.zeros((T+1, 28, 28))\n","\n","\n","plt.figure(figsize=(20, 4))\n","\n","for t in range(T+1):\n","  if t==0:\n","    x[t] = ...\n","  else:\n","    # Echantillonnage d'un bruit gaussien epsilon\n","    epsilon = ...\n","\n","    # Calcul de x_t à partir de x_{t-1}\n","    x[t] = ...\n","\n","    # Prédiction du bruit présent dans x_t par le réseau\n","    epsilon_theta_xt_t = ...\n","\n","    # Débruitage de l'image pour essayer de retrouver x_0\n","    denoised[t] = ...\n","\n","  plt.subplot(2, T+1, t+1)\n","  plt.title(f't={t}')\n","  plt.imshow(x[t], cmap='gray')\n","  plt.axis('off')\n","\n","  plt.subplot(2, T+1, T+1 + t+1)\n","  plt.imshow(denoised[t], cmap='gray')\n","  plt.axis('off')\n","\n","plt.show()\n"],"metadata":{"id":"uXRbu_GU5Q8u"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Échantillonnage de nouvelles images à partir d'un bruit\n","\n","Il reste à implémenter la génération à proprement parler, avec l'algorithme suivant :\n","\n","<center> <img src=\"https://drive.google.com/uc?id=12pwKwswKSnPXfxv9c4hevW-embVvLJRt\" width=500></center>"],"metadata":{"id":"W6KEuSPAgyj1"}},{"cell_type":"code","source":["### A COMPLETER ###\n","# Echantillonnage d'un bruit gaussien comme point de départ\n","x_T = np.random.normal(0, 1, (28, 28))\n","\n","# On prépare le vecteur des x_t que l'on va remplir au fur et à mesure, mais cette\n","# fois ci de T à 0\n","x = np.zeros((T+1, 28, 28))\n","x[T] = x_T\n","\n","\n","plt.figure(figsize=(20, 5))\n","\n","\n","for t in ... :\n","  if t>1:\n","    # Echantillonnage d'un bruit gaussien z\n","    z = ...\n","  else:\n","    # A la fin, on positionne z comme une matrice de zéros\n","    z = ...\n","\n","  # Prédiction du bruit présent dans x_t par le réseau\n","  epsilon_theta_xt_t = ...\n","\n","  # Génération d'un x_{t-1} à partir de x_t et z\n","  x[t-1] = ...\n","\n","  plt.subplot(1, T+1, T+1 - t)\n","  plt.title(f't={t}')\n","  plt.imshow(x[t], cmap='gray')\n","  plt.axis('off')\n","\n","\n","plt.subplot(1, T+1, T+1)\n","plt.title(f't={0}')\n","plt.imshow(x[0], cmap='gray')\n","plt.axis('off')\n","\n","plt.show()"],"metadata":{"id":"ORy2utF2gx1y"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Le bloc suivant vous permettra de générer directement 50 images, afin d'avoir une idée de la qualité (ou de la médiocrité !) générale de la génération"],"metadata":{"id":"31CXwyql-e2K"}},{"cell_type":"code","source":["### A COMPLETER ###\n","# Création de 50 images de bruit de taille 28x28 simultanément\n","x_T = ...\n","\n","# Cette fois-ci, inutile de conserver les générations intermédiaires\n","# On va mettre à jour la variable x_t à chaque étape de la diffusion inverse\n","x_t = x_T\n","\n","for t in ... :\n","  if t>1:\n","    # Echantillonnage d'un bruit gaussien z\n","    z = ...\n","  else:\n","    # A la fin, on positionne z comme une matrice de zéros\n","    z = ...\n","\n","  # Prédiction du bruit présent dans x_t par le réseau\n","  epsilon_theta_xt_t = ...\n","\n","  # Génération d'un x_{t-1} à partir de x_t et z\n","  x_t = ...\n","\n","plt.figure(figsize=(20, 10))\n","\n","for i in range(50):\n","  plt.subplot(5, 10, i+1)\n","  plt.imshow(x_t[i], cmap='gray')\n","  plt.axis('off')\n","\n","plt.show()"],"metadata":{"id":"owUvPX6Rt5J5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Si votre génération n'est pas satisfaisante, il est possible que les 20 epochs n'aient pas été suffisantes pour bien entraîner votre réseau. N'hésitez pas à relancer l'apprentissage un peu plus longtemps.\n","\n","**Exercice complémentaire** :\n","\n","Si jamais vous terminez rapidement, il reste une dernière chose intéressante à implémenter : la génération conditionnelle. Plutôt que de générer un chiffre au hasard, on peut conditionner la génération en fournissant une 3e entrée au réseau : le label que l'on veut générer. Comme on dispose de la variable y_train, il est facile de modifier la Sequence pour ajouter cette 3e entrée. Il vous faudra ensuite modifier le UNet et les codes de génération pour prendre en compte cette nouvelle entrée."],"metadata":{"id":"ecenppAh_h5t"}}]}